{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURE library testing notebook\n",
    "Welocme to the SURE library testing notebook!\n",
    "\n",
    "Use this notebook and the indications in the code boxes as a guideline to test the functionalities of the SURE library for Synthetic Data utility and privacy assessment. \\\n",
    "Feel free to explore and experiment with the library's features beyond these suggestions!\n",
    "\n",
    "Besides this notebook and the [link](https://dario-brunelli-clearbox-ai.notion.site/SURE-Documentation-2c17db370641488a8db5bce406032c1f) to the documentation relative to the SURE library, you are provided with a Google Drive folder containing:\n",
    "- a final questionnaire to gather your feedback.\n",
    "- a consent form to process your feedback information\n",
    "- three *.csv* files (described below)\n",
    "\n",
    "After completing the testing, please fill in the feedback questionnaire and upload this notebook, the questionnaire and the signed consent form to the Google Drive folder.\n",
    "\n",
    "### Datasets description\n",
    "\n",
    "The three datasets provided are the following:\n",
    "\n",
    "- *census_dataset_training.csv*\n",
    "    \n",
    "    The original real dataset used to train the generative model from which *census_dataset_synthetic* was produced.\n",
    "    \n",
    "- *census_dataset_validation.csv*\n",
    "    \n",
    "    This dataset was also part of the original real dataset, but it was not used to train the generative model that produced *census_dataset_synthetic.*\n",
    "    \n",
    "- *census_dataset_synthetic.csv*\n",
    "    \n",
    "    The synthetic dataset produced with the generative model trained on *census_dataset_training.*\n",
    "    \n",
    "\n",
    "The three census datasets include various demographic, social, economic, and housing characteristics of individuals. Every row of the datasets coresponds to an individual.\n",
    "\n",
    "The machine learning task related to these datasets is a classification task, where, based on all the features, a ML classifier model must decide whether the individual earns more than 50k dollars per year (lable=1) or less (lable=0).\\\n",
    "The column \"label\" in each dataset is the ground truth for this classification task.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "Below is a list of tasks. Please use them as general guidelines to proceed. Note that some tasks are deliberately open-ended to give you the freedom to approach them as you see fit and to test the clarity of the provided documentation:\n",
    "\n",
    "1. Install the library.\n",
    "2. Prepare the three datasets using the Preprocessor, adjusting its parameters as you deem best.\n",
    "3. Assess the TSTR (Train on Synthetic, Test on Real) performance of the synthetic dataset on the classification task employing the utility modules (see [Section 4.1](https://www.notion.so/4-ML-Utility-Metrics-ac98a1d294b1428f8b67936323c7c569?pvs=21) of the documentation).\n",
    "4. Evaluate the vulnerability of the synthetic dataset provided to membership inference attacks.\n",
    "5. Generate and explore the final report.\n",
    "\n",
    "Some suggestions on how to proceed are also available in comments in code blocks of the notebook you have been provided with.\n",
    "\n",
    "To perform the task, please refer to the documentation provided.\n",
    "\n",
    "Feel free to test the library in any other way you can think of to challenge the libraryâ€™s capabilities!\n",
    "\n",
    "(e.g. test different datasets than the ones provided)\n",
    "\n",
    "If you have any doubt on how to procede during the testing, try searching for what you need in these reference links:\n",
    "- [Documentation](https://dario-brunelli-clearbox-ai.notion.site/SURE-Documentation-2c17db370641488a8db5bce406032c1f)\n",
    "- [GitHub page](https://github.com/Clearbox-AI/SURE)\n",
    "\n",
    "### Questions\n",
    "Answer the following questions with the results you found (just make sure that the answers are visible in the notebook before uploading it to the Google Drive folder):\n",
    "\n",
    "1. What is the accuracy of the original dataset and the one of the synthetic dataset on the given classification task?\n",
    "2. Which machine learning model has the highest accuracy on the TSTR task?\n",
    "3. What is the percentage of DCRs closer to the training set than to the validation set you found?\n",
    "4. What is the Membership Inference (MI) mean risk score you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the SURE library \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Datasets preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the datasets with the Preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Statistical properties and mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistical properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features mutual information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ML utility - Train on Synthetic Test on Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the machine learning utility of the synthetic dataset on the classification task\n",
    "# Use the real dataset as validation set for the calssification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Privacy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Distance to closest record (DCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distances to closest record between the synthetic dataset and the real dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any clones shared between the synthetic and real datasets (DCR=0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some general statistcs for the DCR array computed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the share of records that are closer to the training set than to the validation set\n",
    "# For this task you need to compute also the DCR between the synthetic dataset and the validation dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Membership Inference Attack test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a Membership inference Attack on your syntehtic dataset\n",
    "# To do so, you'll need to produce an adversary dataset and some labels as adversary guesses groundtruth\n",
    "\n",
    "# hint: the label is automatically produced by the function adversary_dataset and is added as a column named \n",
    "# \"privacy_test_is_training\" in the adversary dataset returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility-Privacy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the utility privacy report with the information computed above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for taking part to the SURE library testing! Your feedback is of great value for us to improve the library!\n",
    "\n",
    "When you have finished testing the library, make sure that the answers to the questions are visible and then upload the notebook to the Google Drive folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
