{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURE library use case notebook\n",
    "Useful links:\n",
    "- [Github repo](https://github.com/Clearbox-AI/SURE)\n",
    "- [Documentation](https://dario-brunelli-clearbox-ai.notion.site/SURE-Documentation-2c17db370641488a8db5bce406032c1f)\n",
    "- [Datasets for testing](https://drive.google.com/drive/folders/1OP1TsRHOCRVc2znSV45kHiiX7Niz2uQ2)\n",
    "\n",
    "Download the datasets and try out the library with this set-by-step guided use case.\n",
    "\n",
    "We would gratly appreciate your feedback to help us improve the library! \\\n",
    "If you encounter any issues, please open an issue on our [GitHub repository](https://github.com/Clearbox-AI/SURE).\n",
    "\n",
    "### Datasets description\n",
    "\n",
    "The three datasets provided are the following:\n",
    "\n",
    "- *census_dataset_training.csv* \\\n",
    "    The original real dataset used to train the generative model from which *census_dataset_synthetic* was produced.\n",
    "    \n",
    "- *census_dataset_validation.csv* \\\n",
    "    This dataset was also part of the original real dataset, but it was not used to train the generative model that produced \n",
    "    \n",
    "- *census_dataset_synthetic.csv* \\\n",
    "    The synthetic dataset produced with the generative model trained on *census_dataset_training.*\n",
    "    \n",
    "\n",
    "The three census datasets include various demographic, social, economic, and housing characteristics of individuals. Every row of the datasets coresponds to an individual.\n",
    "\n",
    "The machine learning task related to these datasets is a classification task, where, based on all the features, a ML classifier model must decide whether the individual earns more than 50k dollars per year (lable=1) or less (lable=0).\\\n",
    "The column \"label\" in each dataset is the ground truth for this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installing the library and importing dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the SURE library \n",
    "%pip install clearbox-sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import polars as pl # you can use polars or pandas for importing the datasets\n",
    "\n",
    "from sure import Preprocessor, report\n",
    "from sure.utility import (compute_statistical_metrics, compute_mutual_info,\n",
    "\t\t\t  compute_utility_metrics_class)\n",
    "from sure.privacy import (distance_to_closest_record, dcr_stats, number_of_dcr_equal_to_zero, validation_dcr_test, \n",
    "\t\t\t  adversary_dataset, membership_inference_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset import and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = pl.scan_csv(\"census_dataset_training.csv\")\n",
    "valid_data = pl.scan_csv(\"census_dataset_validation.csv\")\n",
    "synth_data = pl.scan_csv(\"census_dataset_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Datasets preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the datasets with the Preprocessor\n",
    "\n",
    "# Real dataset - Preprocessor initialization and query exacution\n",
    "preprocessor            = Preprocessor(real_data, get_discarded_info=False)\n",
    "real_data_preprocessed  = preprocessor.transform(real_data, num_fill_null='forward', scaling='standardize')\n",
    "\n",
    "# Validation dataset - Preprocessor initialization and query exacution\n",
    "preprocessor            = Preprocessor(valid_data, get_discarded_info=False)\n",
    "valid_data_preprocessed = preprocessor.transform(valid_data, num_fill_null='forward', scaling='standardize')\n",
    "\n",
    "# Synthetic dataset - Preprocessor initialization and query exacution\n",
    "preprocessor            = Preprocessor(synth_data, get_discarded_info=False)\n",
    "synth_data_preprocessed = preprocessor.transform(synth_data, num_fill_null='forward', scaling='standardize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utility assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Statistical properties and mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistical properties and features mutual information\n",
    "num_features_stats, cat_features_stats, temporal_feat_stats = compute_statistical_metrics(real_data_preprocessed, synth_data_preprocessed)\n",
    "corr_real, corr_synth, corr_difference                      = compute_mutual_info(real_data_preprocessed, synth_data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 ML utility - Train on Synthetic Test on Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing the machine learning utility of the synthetic dataset on the classification task\n",
    "\n",
    "# ML utility: TSTR - Train on Synthetic, Test on Real\n",
    "X_train      = real_data_preprocessed.drop(\"label\") # Assuming the datasets have a “label” column for the machine learning task they are intended for\n",
    "y_train      = real_data_preprocessed[\"label\"]\n",
    "X_synth      = synth_data_preprocessed.drop(\"label\")\n",
    "y_synth      = synth_data_preprocessed[\"label\"]\n",
    "X_test       = valid_data_preprocessed.drop(\"label\").limit(10000) # Test the trained models on a portion of the original real dataset (first 10k rows)\n",
    "y_test       = valid_data_preprocessed[\"label\"].limit(10000)\n",
    "TSTR_metrics = compute_utility_metrics_class(X_train, X_synth, X_test, y_train, y_synth, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Privacy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Distance to closest record (DCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distances to closest record between the synthetic dataset and the real dataset\n",
    "# and the distances to closest record between the synthetic dataset and the validation dataset\n",
    "\n",
    "dcr_synth_train = distance_to_closest_record(\"synth_train\", synth_data_preprocessed, real_data_preprocessed)\n",
    "dcr_synth_valid = distance_to_closest_record(\"synth_val\", synth_data_preprocessed, valid_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any clones shared between the synthetic and real datasets (DCR=0).\n",
    "\n",
    "dcr_zero_synth_train  = number_of_dcr_equal_to_zero(\"synth_train\", dcr_synth_train)\n",
    "dcr_zero_synth_valid  = number_of_dcr_equal_to_zero(\"synth_val\", dcr_synth_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some general statistcs for the DCR arrays computed above\n",
    "\n",
    "dcr_stats_synth_train = dcr_stats(\"synth_train\", dcr_synth_train)\n",
    "dcr_stats_synth_valid = dcr_stats(\"synth_val\", dcr_synth_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the share of records that are closer to the training set than to the validation set\n",
    "\n",
    "share = validation_dcr_test(dcr_synth_train, dcr_synth_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Membership Inference Attack test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a Membership inference Attack on your syntehtic dataset\n",
    "# To do so, you'll need to produce an adversary dataset and some labels as adversary guesses groundtruth\n",
    "\n",
    "# The label is automatically produced by the function adversary_dataset and is added as a column named \n",
    "# \"privacy_test_is_training\" in the adversary dataset returned\n",
    "\n",
    "# ML privacy attack sandbox initialization and simulation\n",
    "adversary_dataset = adversary_dataset(real_data_preprocessed, valid_data_preprocessed)\n",
    "\n",
    "# The function adversary_dataset adds a column \"privacy_test_is_training\" to the adversary dataset, indicating whether the record was part of the training set or not\n",
    "adversary_guesses_ground_truth = adversary_dataset[\"privacy_test_is_training\"] \n",
    "MIA = membership_inference_test(adversary_dataset, synth_data_preprocessed, adversary_guesses_ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Utility-Privacy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the utility privacy report with the information computed above\n",
    "\n",
    "report(real_data, synth_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
